train_path = data/datasets/zhmsra/zhmsra_train_context.json
valid_path = data/datasets/zhmsra/zhmsra_dev_context.json
save_path = data/zhmsra/
save_path_include_iteration = False
init_eval = False
save_optimizer = False
train_log_iter = 1
final_eval = False
train_batch_size = 8
epochs = 100
lr = 5e-06
lr_warmup = 0.1
weight_decay = 0.01
max_grad_norm = 1.0
match_solver = hungarian
type_loss = celoss
nil_weight = -1.0
match_boundary_weight = 1.0
match_class_weight = 1.0
loss_boundary_weight = 1.0
loss_class_weight = 1.0
match_boundary_type = logp
repeat_gt_entities = 60
eval_every_epochs = 1
eval_test = False
config = configs/zhmsra.conf
local_rank = -1
world_size = -1
types_path = data/datasets/zhmsra/zhmsra_types.json
tokenizer_path = hfl/chinese-bert-wwm-ext
lowercase = False
sampling_processes = 4
label = zhmsra_train
log_path = data/zhmsra/
store_predictions = False
store_examples = False
example_count = None
debug = False
save_code = True
lstm_layers = 2
span_attn_layers = 2
wo_self_attn = False
wo_cross_attn = False
split_epoch = 10
stage_one_lr_scale = 2.0
prop_drop = 0.1
soi_pooling = lrconcat
pos_type = sine
num_proposals = 60
sampling_timesteps = 5
beta_schedule = cosine
timesteps = 1000
step_embed_type = add
sample_dist_type = normal
scale = 1.0
extand_noise_spans = concat
span_renewal = False
step_ensemble = False
device_id = 3
model_path = hfl/chinese-bert-wwm-ext
model_type = diffusionner
cpu = False
eval_batch_size = 32
pool_type = max
no_overlapping = True
no_partial_overlapping = True
no_duplicate = False
boundary_threshold = 0.0
cls_threshold = 0.0
entity_threshold = 2.5
seed = 488
cache_path = None